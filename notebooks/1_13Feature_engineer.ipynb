{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform str feature in to values so that it can be use in the model \n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "def feature_tovalue (input_file, output_file):\n",
    "# this function is to transform some features in to a value form for the modelling later such as the bus train tram distance , schoolr rank\n",
    "# such as shopping center distance \n",
    "# input_file: the csv file needed to add in more features \n",
    "# output_file: is the csv name and the output path of the merged/adjusted csv file\n",
    "    bus_distance_value_list=[]\n",
    "    tram_distance_value_list=[]\n",
    "    train_distance_value_list=[]\n",
    "    country_train_distance_value_list=[]\n",
    "    df = pd.read_csv(input_file)\n",
    "    school_rank_value_list =[]\n",
    "    walk_time_list =[]\n",
    "    drive_time_list =[]\n",
    " \n",
    "    # clean the data first \n",
    "    new_column_names = {'crime_rate_per 100,000 population': 'Crime_rate', 'Population_density': 'Pop_density'}\n",
    "    df = df.rename(columns=new_column_names)\n",
    "    df['cost_text'] = pd.to_numeric(df['cost_text'], errors='coerce')\n",
    "    \n",
    "    df = df[(df['Beds'] != 0) & \n",
    "                (df['Baths'] != 0) & \n",
    "                (df['cost_text']>50)\n",
    "                ] \n",
    "    df = df.dropna( subset=['SA2_code'])\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Add transport value \n",
    "    for count in range (len(df)):\n",
    "        # add school rank value \n",
    "        # for each property nearby schools \n",
    "        top_rank = 650\n",
    "        for i in df[\"School_with_rank\"][count].split(\"],\"):\n",
    "            \n",
    "            string=  i.split(\",\")[2]\n",
    "            pattern = r\"(?:None|\\d+)\"\n",
    "            matches = re.findall(pattern, string)\n",
    "            # to get the nearby school rank \n",
    "            if matches[0]!=\"None\":\n",
    "                rank = int(matches[0])\n",
    "                if rank<top_rank:\n",
    "                    top_rank = rank\n",
    "        \n",
    "        school_rank_value_list.append(top_rank/650)\n",
    "        \n",
    "        \n",
    "        walk_time = 8200\n",
    "        drive_time=1100\n",
    "        if not pd.isna(df[\"driving distance/time\"][count]):\n",
    "            drive_time= df[\"driving distance/time\"][count].split(\"/\")[1]\n",
    "            walk_time=df[\"walking distance/time\"][count].split(\"/\")[1]\n",
    "        \n",
    "        walk_time_list.append(walk_time)\n",
    "        drive_time_list.append(drive_time)\n",
    "        \n",
    "        try:\n",
    "            pattern = r'\\d+\\.\\d+'\n",
    "            match = re.search(pattern, df[\"Nearest_Bus_Stop\"].iloc[count].split(\",\")[3])\n",
    "            \n",
    "            bus_distance_value  = float(float(match.group(0))/3)\n",
    "            bus_distance_value_list.append(bus_distance_value)\n",
    "        except AttributeError :\n",
    "            bus_distance_value = 1\n",
    "            bus_distance_value_list.append(bus_distance_value)\n",
    "        \n",
    "        try:\n",
    "            match = re.search(pattern, df[\"Nearest_Tram_Stop\"].iloc[count].split(\",\")[3])\n",
    "            tram_distance_value  = float(float(match.group(0))/5)\n",
    "            tram_distance_value_list.append(tram_distance_value)\n",
    "        except AttributeError :\n",
    "            tram_distance_value = 1\n",
    "            tram_distance_value_list.append(tram_distance_value)\n",
    "            \n",
    "        try:\n",
    "            match = re.search(pattern, df[\"Nearest_Metro_Train_Station\"].iloc[count].split(\",\")[3])\n",
    "            train_distance_value  = float(float(match.group(0))/10)\n",
    "            train_distance_value_list.append(train_distance_value)\n",
    "        except AttributeError :\n",
    "            train_distance_value = 1\n",
    "            train_distance_value_list.append(train_distance_value)\n",
    "        try:\n",
    "            match = re.search(pattern, df[\"Nearest_Regional_Train_Station\"].iloc[count].split(\",\")[3])\n",
    "            country_train_distance_value  = float(float(match.group(0))/30)\n",
    "            country_train_distance_value_list.append(country_train_distance_value)\n",
    "        except AttributeError :\n",
    "            country_train_distance_value = 1\n",
    "            country_train_distance_value_list.append(country_train_distance_value)\n",
    "            \n",
    "    \n",
    "    df[\"school_rank_value\"] = school_rank_value_list \n",
    "    df[\"bus_value\"]=bus_distance_value_list\n",
    "    df[\"tram_value\"]= tram_distance_value_list\n",
    "    df[\"train_value\"]=train_distance_value_list\n",
    "    df[\"country_train\"]= country_train_distance_value_list\n",
    "    df[\"walk_time\"]=walk_time_list\n",
    "    df[\"drive_time\"]=drive_time_list\n",
    "    if not os.path.exists(\"../data/curated/twelveth_clean\"):\n",
    "        os.makedirs(\"../data/curated/twelveth_clean\")\n",
    "            \n",
    "    df.to_csv(output_file,index = False )\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_tovalue(\"../data/curated/eleventh_clean/apartment_1.csv\",\"../data/curated/twelveth_clean/apartment_1.csv\")\n",
    "feature_tovalue(\"../data/curated/eleventh_clean/apartment_2.csv\",\"../data/curated/twelveth_clean/apartment_2.csv\")\n",
    "feature_tovalue(\"../data/curated/eleventh_clean/apartment_3.csv\",\"../data/curated/twelveth_clean/apartment_3.csv\")\n",
    "feature_tovalue(\"../data/curated/eleventh_clean/apartment_4.csv\",\"../data/curated/twelveth_clean/apartment_4.csv\")\n",
    "feature_tovalue(\"../data/curated/eleventh_clean/apartment_5.csv\",\"../data/curated/twelveth_clean/apartment_5.csv\")\n",
    "\n",
    "feature_tovalue(\"../data/curated/eleventh_clean/house_1.csv\",\"../data/curated/twelveth_clean/house_1.csv\")\n",
    "feature_tovalue(\"../data/curated/eleventh_clean/house_2.csv\",\"../data/curated/twelveth_clean/house_2.csv\")\n",
    "feature_tovalue(\"../data/curated/eleventh_clean/house_3.csv\",\"../data/curated/twelveth_clean/house_3.csv\")\n",
    "feature_tovalue(\"../data/curated/eleventh_clean/house_4.csv\",\"../data/curated/twelveth_clean/house_4.csv\")\n",
    "\n",
    "feature_tovalue(\"../data/curated/eleventh_clean/town_house.csv\",\"../data/curated/twelveth_clean/town_house.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part is not a function it combines all the apartment csv and store it in the ../data/cruated/final_clean \n",
    "if not os.path.exists(\"../data/curated/final_data\"):\n",
    "    os.makedirs(\"../data/curated/final_data\")\n",
    "dfs = []\n",
    "file_paths = [\"../data/curated/twelveth_clean/apartment_1.csv\", \"../data/curated/twelveth_clean/apartment_2.csv\", \"../data/curated/twelveth_clean/apartment_3.csv\",\n",
    "              \"../data/curated/twelveth_clean/apartment_4.csv\", \"../data/curated/twelveth_clean/apartment_5.csv\"]  # Add the file paths for your CSV files\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "merged_df_apartment = pd.concat(dfs, ignore_index=True)\n",
    "merged_df_apartment.to_csv(\"../data/curated/final_data/apartment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part is not a function it combines all the house csv and store it in the ../data/cruated/final_clean \n",
    "dfs = []\n",
    "file_paths = [\"../data/curated/twelveth_clean/house_1.csv\", \"../data/curated/twelveth_clean/house_3.csv\",\n",
    "              \"../data/curated/twelveth_clean/house_2.csv\", \"../data/curated/twelveth_clean/house_4.csv\"]  # Add the file paths for your CSV files\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "merged_df_house = pd.concat(dfs, ignore_index=True)\n",
    "merged_df_house.to_csv(\"../data/curated/final_data/house.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part is not a function it combines all the townhouse csv and store it in the ../data/cruated/final_clean \n",
    "df = pd.read_csv(\"../data/curated/twelveth_clean/town_house.csv\")\n",
    "df.to_csv(\"../data/curated/final_data/town_house.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
